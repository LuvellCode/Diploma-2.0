{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ! Realtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import multiprocess as mp\n",
    "import gc\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentile_calc(data, groupby_col, num_cols, percentile_list):\n",
    "    non_numeric = [col_name for col_name in data.columns if col_name not in num_cols]\n",
    "    for qu in percentile_list: \n",
    "        percentiles = data.groupby(groupby_col).quantile(q=qu/100).reset_index()\n",
    "        cols_to_change = {col : col +'_' + str(qu) for col in num_cols}\n",
    "        percentiles.rename(columns=cols_to_change, inplace=True)\n",
    "        if qu == percentile_list[0]:\n",
    "            all_percentiles = percentiles\n",
    "        else:\n",
    "            all_percentiles = pd.merge(all_percentiles, percentiles, how = \"left\",\\\n",
    "                                       on = non_numeric)\n",
    "    return all_percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _drop_correlated(data, score_ordered_cols, max_corr, method='pearson'):\n",
    "    new = [[score_ordered_cols[0]], [0]]\n",
    "    corr_matrix = data[score_ordered_cols].corr(method).values\n",
    "    N = len(score_ordered_cols)\n",
    "    for i in range(1, N):\n",
    "        tr = corr_matrix[new[1], i]\n",
    "        if sum(np.abs(tr) > max_corr) == 0:\n",
    "            new[0] += [score_ordered_cols[i]]\n",
    "            new[1] += [i]\n",
    "    return new[0]\n",
    "\n",
    "\n",
    "class feature_reduction(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, min_mi=.001, max_corr=.7, n_neighbors=11):\n",
    "        self.min_mi = min_mi\n",
    "        self.max_corr = max_corr\n",
    "        self.n_neighbors = n_neighbors\n",
    "\n",
    "    def fit(self, X:pd.DataFrame, y):\n",
    "        X = X.copy(deep=True)\n",
    "        columns = X.columns\n",
    "        mi = mutual_info_classif(X.values, y, n_neighbors= self.n_neighbors)\n",
    "        cols_mi = list(zip(columns, mi))\n",
    "        cols_mi.sort(reverse=True, key=lambda x: x[1])\n",
    "        cols_mi = [pair[0] for pair in cols_mi if pair[1] > self.min_mi]\n",
    "        new_cols = _drop_correlated(X[cols_mi], cols_mi, max_corr=self.max_corr)\n",
    "        self.selected_cols = new_cols\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.selected_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_and_counts(s):\n",
    "    # Imports/sets here because it'd be executed in subroutine which executes independently from main code\n",
    "    import ftfy, re, numpy as np\n",
    "    from string import punctuation, whitespace\n",
    "    \n",
    "    # Всі коди дефісу(або аналогічних символів) які я знайшов в текстах\n",
    "    dashes = [chr(int(d, 16)) for d in ['058A', '05BE', '1400', '1806', '2010', '2011',\\\n",
    "          '2012', '2013', '2014', '2015', '2053', '207B', '208B', '2212', '2E17', \\\n",
    "          '2E1A', '2E3A', '2E3B', '2E40', '2E5D', '301C', '3030', '30A0', 'FE31', \\\n",
    "          'FE32', 'FE58', 'FE63', 'FF0D', '10EAD']]\n",
    "    dashes_compiled = re.compile('[' + ''.join(dashes) + ']+', flags = re.UNICODE)\n",
    "    \n",
    "    s = ftfy.fix_text(s)\n",
    "    s = re.sub(dashes_compiled, '-', s)     # all dashes should be the same\n",
    "\n",
    "    url_n = len(re.findall('https?://\\\\S+\\\\b', s)) # count urls\n",
    "    s = re.sub('https?://\\\\S+\\\\b', '', s)   # and remove them\n",
    "\n",
    "    hasht_n = len(re.findall(r'#\\w+\\b', s)) # count hashtags\n",
    "    s = re.sub(r'#\\w+\\b', '', s)            # remove them\n",
    "\n",
    "    handle_n = len(re.findall(r'@\\w{1,15}\\b', s)) # count handles\n",
    "    s = re.sub(r'@\\w{1,15}\\b', '', s)       # remove them\n",
    "\n",
    "    s = re.sub('pic\\\\.twitter\\\\.com/\\\\w+\\\\b', '', s)        # remove pictures. Not expected to impact overall picture\n",
    "    s = re.sub('\\\\s+', ' ', s)                              # reducing multiple whitespaces to one\n",
    "    s = s.lstrip(whitespace + punctuation + '\\xa0' + chr(8230))   # removing possible whitespaces in front\n",
    "    s = s.rstrip(whitespace + '\\xa0')         # and on the back\n",
    "    l=''\n",
    "    emoj_and_such = 0\n",
    "    for ch in s:\n",
    "        if ord(ch) < 8204:\n",
    "            l += ch             # keep a symbol if not emoji or pictogram or such\n",
    "        else:\n",
    "            emoj_and_such += 1  # counting emojis and pictograms\n",
    "    comma_n = len(re.findall(',', s))\n",
    "    exl_n =  len(re.findall('!', s))\n",
    "    dash_n = len(re.findall('-', s))\n",
    "    a_an_n = len(re.findall(r'\\b[Aa]n?\\b', s))\n",
    "    the_n = len(re.findall(r'\\b[Tt]he\\b', s))\n",
    "\n",
    "    # reduce a number of repeated symbols to no more than 2 \n",
    "    l = re.sub(r'(.)\\1\\1+', r'\\1\\1', l)\n",
    "    length = len(l)\n",
    "\n",
    "    words = [len(w) for w in re.findall(r'\\b\\w+\\b', l)]\n",
    "    if len(words)==0:\n",
    "        average_word = 0\n",
    "    else:\n",
    "        average_word = np.max(words)\n",
    "    \n",
    "    return l, url_n, hasht_n, handle_n, emoj_and_such, exl_n, comma_n, dash_n, a_an_n, the_n, length, average_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "model = joblib.load('model_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 108 entries, 0 to 107\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   account  108 non-null    object\n",
      " 1   tweet    108 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.8+ KB\n",
      "Index(['account', 'tweet', 'tuple', 'cleaned_tweet', 'url_n', 'hasht_n',\n",
      "       'handle_n', 'emoji_and_such', 'exl_n', 'comma_n', 'dash_n', 'a_an_n',\n",
      "       'the_n', 'length', 'average_word'],\n",
      "      dtype='object')\n",
      "    account                                              tweet  \\\n",
      "0    10_GOP  \"We have a sitting Democrat US Senator on tria...   \n",
      "1    10_GOP  Marshawn Lynch arrives to game in anti-Trump s...   \n",
      "2    10_GOP  Daughter of fallen Navy Sailor delivers powerf...   \n",
      "3    10_GOP  JUST IN: President Trump dedicates Presidents ...   \n",
      "4    10_GOP  19,000 RESPECTING our National Anthem! #StandF...   \n",
      "..      ...                                                ...   \n",
      "103  10_GOP  Trump after military meeting \"It's the calm be...   \n",
      "104  10_GOP  Dear @YouTube @TeamYouTube,  Your response is ...   \n",
      "105  10_GOP  Rep. @SteveScalise started off Game 1 of the N...   \n",
      "106  10_GOP  How many of those raging over Mike Pence exerc...   \n",
      "107  10_GOP  Mike Pence is such a great man and Patriot! I'...   \n",
      "\n",
      "                                         cleaned_tweet  url_n  hasht_n  \\\n",
      "0    We have a sitting Democrat US Senator on trial...      1        0   \n",
      "1    Marshawn Lynch arrives to game in anti-Trump s...      1        0   \n",
      "2    Daughter of fallen Navy Sailor delivers powerf...      1        1   \n",
      "3    JUST IN: President Trump dedicates Presidents ...      1        0   \n",
      "4               19,00 RESPECTING our National Anthem!       1        1   \n",
      "..                                                 ...    ...      ...   \n",
      "103  Trump after military meeting \"It's the calm be...      1        0   \n",
      "104  Dear , Your response is bullshit. It's not tru...      1        0   \n",
      "105  Rep. started off Game 1 of the National League...      2        0   \n",
      "106  How many of those raging over Mike Pence exerc...      0        0   \n",
      "107  Mike Pence is such a great man and Patriot! I'...      1        0   \n",
      "\n",
      "     handle_n  emoji_and_such  exl_n  comma_n  dash_n  a_an_n  the_n  length  \\\n",
      "0           1               0      0        0       0       2      1     122   \n",
      "1           0               0      0        0       1       0      1     116   \n",
      "2           0               0      0        1       0       0      0     106   \n",
      "3           0               0      0        1       0       0      1     121   \n",
      "4           0               2      1        1       0       0      0      38   \n",
      "..        ...             ...    ...      ...     ...     ...    ...     ...   \n",
      "103         0               0      0        0       0       0      2     126   \n",
      "104         2               0      0        1       0       0      0      82   \n",
      "105         1               0      0        0       0       0      2     102   \n",
      "106         0               0      0        0       0       0      2     139   \n",
      "107         0               0      1        0       0       1      1     105   \n",
      "\n",
      "     average_word  \n",
      "0              10  \n",
      "1               8  \n",
      "2               9  \n",
      "3              10  \n",
      "4              10  \n",
      "..            ...  \n",
      "103             9  \n",
      "104             8  \n",
      "105            10  \n",
      "106            10  \n",
      "107             9  \n",
      "\n",
      "[108 rows x 14 columns]\n",
      "  account  tweet_count\n",
      "0  10_GOP          108\n",
      "Restricted\n",
      "  account  url_n_10  hasht_n_10  handle_n_10  emoji_and_such_10  exl_n_10  \\\n",
      "0  10_GOP       0.0         0.0          0.0                0.0       0.0   \n",
      "\n",
      "   comma_n_10  dash_n_10  a_an_n_10  the_n_10  ...  hasht_n_90  handle_n_90  \\\n",
      "0         0.0        0.0        0.0       0.0  ...         1.0          1.0   \n",
      "\n",
      "   emoji_and_such_90  exl_n_90  comma_n_90  dash_n_90  a_an_n_90  the_n_90  \\\n",
      "0                0.3       1.0         1.3        0.0        1.0       2.0   \n",
      "\n",
      "   length_90  average_word_90  \n",
      "0      138.0             11.3  \n",
      "\n",
      "[1 rows x 100 columns]\n",
      "Proba: [0.0202602 0.9797398]\n",
      "\n",
      "Prediction: BOT Detected\n",
      "Troll Account Probability: 0.9797398011658849\n"
     ]
    }
   ],
   "source": [
    "# msg = \"\"\"Dan Bongino: \"\"Nobody trolls liberals better than Donald Trump.\"\" Exactly!  https://t.co/AigV93aC8J #asd #sdhfj #asd #asd #asd \"\"\"\n",
    "# test_tweet = [{\"account\": \"Me My Mus\", \"tweet\": msg},\n",
    "#               {\"account\": \"Me My Mus\", \"tweet\": msg},\n",
    "#               {\"account\": \"Me My Mus\", \"tweet\": msg},\n",
    "#               {\"account\": \"Me My Mus\", \"tweet\": msg},\n",
    "#               {\"account\": \"Me My Mus\", \"tweet\": msg},\n",
    "#               {\"account\": \"Me My Mus\", \"tweet\": msg},\n",
    "#               {\"account\": \"Me My Mus\", \"tweet\": msg},\n",
    "#               {\"account\": \"Me My Mus\", \"tweet\": msg},\n",
    "#               {\"account\": \"Me My Mus\", \"tweet\": msg},\n",
    "#               {\"account\": \"Me My Mus\", \"tweet\": msg},\n",
    "#               ]\n",
    "#test_df = pd.DataFrame(test_tweet)\n",
    "\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "test_df = test_df[['account', 'tweet']]\n",
    "#test_df.to_csv(\"test_data.csv\", index=False)\n",
    "test_df.info()\n",
    "\n",
    "# Cleaning\n",
    "with mp.Pool(processes= mp.cpu_count()) as p:\n",
    "    test_df['tuple'] = p.map(cleaning_and_counts, test_df.tweet)\n",
    "\n",
    "# Memory Optimization\n",
    "features = (\"cleaned_tweet, url_n, hasht_n, handle_n, emoji_and_such, exl_n, comma_n, dash_n, a_an_n, the_n, length, average_word\").split(', ')\n",
    "\n",
    "for i in range(len(features)):\n",
    "    if i ==0:\n",
    "        test_df[features[i]] = test_df.tuple.apply(lambda t: t[i])\n",
    "    else:\n",
    "        test_df[features[i]] = test_df.tuple.apply(lambda t: t[i]).astype(np.uint8)\n",
    "\n",
    "print(test_df.columns)\n",
    "test_df.drop(['tuple'], axis=1,inplace=True)\n",
    "gc.collect()\n",
    "\n",
    "print(test_df)\n",
    "\n",
    "# Check if total account tweets > 10\n",
    "\n",
    "_min_count = 10\n",
    "_acc_properties = test_df[['account']].groupby(['account'])\\\n",
    "    .agg(tweet_count=('account', 'size'))\\\n",
    "    .reset_index()\n",
    "\n",
    "print(_acc_properties)\n",
    "_kept_accs = _acc_properties[_acc_properties.tweet_count >= _min_count]\n",
    "_restricted = test_df[test_df.account.isin(_kept_accs.account)].copy(deep=True)\n",
    "#del total_data\n",
    "\n",
    "_num_cols = features[1:]\n",
    "_restricted.drop(['tweet', 'cleaned_tweet'], axis=1, inplace=True)\n",
    "print(\"Restricted\")\n",
    "_restricted\n",
    "\n",
    "\n",
    "# Generate features\n",
    "_all_percentiles = percentile_calc(_restricted[['account']+_num_cols], \\\n",
    "                                 groupby_col='account', num_cols=_num_cols,\n",
    "                                 percentile_list=range(10, 100, 10))\n",
    "    \n",
    "_new_features = _all_percentiles.columns[2:]\n",
    "print(_all_percentiles)\n",
    "\n",
    "preditction = model.predict(_all_percentiles)\n",
    "prediction_proba = model.predict_proba(_all_percentiles)[0]\n",
    "\n",
    "print(f\"Proba: {prediction_proba}\")\n",
    "\n",
    "\n",
    "print(\"\\nPrediction: \" + (\"BOT Detected\" if preditction == 1 else \"Regular User\"))\n",
    "print(\"Troll Account Probability: \" + str(prediction_proba[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
