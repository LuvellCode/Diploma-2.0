{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ftfy in c:\\users\\ihor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (6.2.3)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in c:\\users\\ihor\\appdata\\roaming\\python\\python312\\site-packages (from ftfy) (0.2.13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\ihor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.2.7)\n",
      "Requirement already satisfied: graphviz in c:\\users\\ihor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ihor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (3.8.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\ihor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\ihor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (2.2.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\ihor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (1.13.0)\n",
      "Requirement already satisfied: plotly in c:\\users\\ihor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (5.20.0)\n",
      "Requirement already satisfied: six in c:\\users\\ihor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ihor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ihor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ihor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ihor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ihor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ihor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ihor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ihor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\ihor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ihor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (3.1.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\ihor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from plotly->catboost) (8.2.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install ftfy\n",
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import re\n",
    "from string import punctuation, whitespace\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import ftfy\n",
    "from sklearn.utils import shuffle\n",
    "import gc\n",
    "import multiprocess as mp\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Reading + Preps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблеми:\n",
    "1. Багато неанглійських мов, що дуже ускладнює класифікацію.\n",
    "    * Рішення: Видалити\n",
    "2. Серед твітів, класифікованих як англійські, є німецькі та російські тексти.\n",
    "    * Рішення: видалити через регекс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#../input/russian-troll-tweets/IRAhandle_tweets_1.csv\n",
    "PATH = \"input/russian-troll-tweets/\"\n",
    "filenames = glob.glob(os.path.join(PATH, \"*.csv\"))\n",
    "full_ru_trolls = pd.concat((pd.read_csv(f) for f in filenames))\n",
    "full_ru_trolls.drop(['external_author_id', 'region', 'harvested_date',\n",
    "        'updates', 'account_type', 'new_june_2018', 'post_type',\n",
    "        'account_category', 'following', 'followers', 'retweet'],\n",
    "        axis=1, inplace=True)\n",
    "\n",
    "full_ru_trolls = full_ru_trolls[full_ru_trolls.content.notnull()]\n",
    "full_ru_trolls['troll'] = 1\n",
    "full_ru_trolls_en = full_ru_trolls[full_ru_trolls.language == 'English'].copy(deep=True)\n",
    "\n",
    "full_ru_trolls_en.rename(columns={'author': 'account', 'content': 'tweet'}, inplace=True)\n",
    "full_ru_trolls_en = full_ru_trolls_en[~full_ru_trolls_en.tweet.str.contains('А-Яа-я')]\n",
    "\n",
    "german_s = re.compile('(Ich )|(Sie )|(Ihnen )|( sich$)|( [Kk]?eine? )|( [Dd]as )|'+\n",
    "           '^[Dd]as |^[Ss]ind | bist | und | sind | (?!(van|von|-)) der |' + \n",
    "           '[ ^][a-z]*ö|[ ^][a-z]*ä|[ ^][a-z]*ü')\n",
    "\n",
    "full_ru_trolls_en = full_ru_trolls_en[~full_ru_trolls_en.tweet.str.contains(german_s)].copy(deep=True)\n",
    "\n",
    "del full_ru_trolls\n",
    "full_ru_trolls_en.drop(['language', 'publish_date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оскільки інфа не має чіткої структури, було прийнято рішення:\n",
    "* Перейменувати всі стовпці імені облікового запису на \"account\", а всі стовпці з твітами - на \"tweet\"\n",
    "* Не використовувати додаткові колонки які є різними для датасетів"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment140 = pd.read_csv('input/sentiment140/training.1600000.processed.noemoticon.csv',\\\n",
    "    encoding = 'Latin-1', names=('target', 'id', 'date', 'flag', 'username','tweet'))\n",
    "\n",
    "sentiment140.drop(['target', 'id', 'date', 'flag'], axis=1, inplace=True)\n",
    "sentiment140.rename(columns={'username': 'account'}, inplace=True)\n",
    "sentiment140['troll'] = 0\n",
    "\n",
    "PATH = \"input/RawTwitterFeeds/\"\n",
    "filenames = glob.glob(os.path.join(PATH, \"*.csv\"))\n",
    "celebs = pd.concat((pd.read_csv(f) for f in filenames))\n",
    "celebs.drop(['Unnamed: 0', 'Unnamed: 0.1','id', 'date', 'link', 'retweet'], axis=1,inplace=True)\n",
    "\n",
    "celebs.rename(columns={'author': 'account', 'text': 'tweet'}, inplace=True)\n",
    "celebs = celebs[celebs.tweet.notnull()]\n",
    "celebs['troll'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Об'єднання в стандартизований фрейм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account</th>\n",
       "      <th>tweet</th>\n",
       "      <th>troll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>various</td>\n",
       "      <td>#DataScience Basics: #DataMining vs. #Statisti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>various</td>\n",
       "      <td>How to Become a #Data Scientist – Part 1: http...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>various</td>\n",
       "      <td>@jesterxl @kdnuggets or just go with @tableau :)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>various</td>\n",
       "      <td>#Boston U. Online MS in Applied #Business #Ana...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>various</td>\n",
       "      <td>#ICYMI Still Searching for ROI in #BigData Ana...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3901570</th>\n",
       "      <td>_YOUR_LIFESTYLE</td>\n",
       "      <td>Like me. Share me. Follow me http://t.co/VvhUO...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3901571</th>\n",
       "      <td>_YOUR_LIFESTYLE</td>\n",
       "      <td>.the main thing is to was love https://t.co/oq...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3901572</th>\n",
       "      <td>_YOUR_LIFESTYLE</td>\n",
       "      <td>Amazing! Found my script: Download ReBuild - W...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3901573</th>\n",
       "      <td>_YOUR_LIFESTYLE</td>\n",
       "      <td>Present Perfect http://t.co/vNu3i2Xh4M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3901574</th>\n",
       "      <td>_YOUR_LIFESTYLE</td>\n",
       "      <td>GoPro SummerStory http://t.co/2afDrn7jWh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3901575 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 account                                              tweet  \\\n",
       "0                various  #DataScience Basics: #DataMining vs. #Statisti...   \n",
       "1                various  How to Become a #Data Scientist – Part 1: http...   \n",
       "2                various   @jesterxl @kdnuggets or just go with @tableau :)   \n",
       "3                various  #Boston U. Online MS in Applied #Business #Ana...   \n",
       "4                various  #ICYMI Still Searching for ROI in #BigData Ana...   \n",
       "...                  ...                                                ...   \n",
       "3901570  _YOUR_LIFESTYLE  Like me. Share me. Follow me http://t.co/VvhUO...   \n",
       "3901571  _YOUR_LIFESTYLE  .the main thing is to was love https://t.co/oq...   \n",
       "3901572  _YOUR_LIFESTYLE  Amazing! Found my script: Download ReBuild - W...   \n",
       "3901573  _YOUR_LIFESTYLE             Present Perfect http://t.co/vNu3i2Xh4M   \n",
       "3901574  _YOUR_LIFESTYLE           GoPro SummerStory http://t.co/2afDrn7jWh   \n",
       "\n",
       "         troll  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "...        ...  \n",
       "3901570      1  \n",
       "3901571      1  \n",
       "3901572      1  \n",
       "3901573      1  \n",
       "3901574      1  \n",
       "\n",
       "[3901575 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_cols = ['account', 'tweet', 'troll']\n",
    "total_data = pd.concat([celebs[used_cols], sentiment140[used_cols], full_ru_trolls_en[used_cols]], ignore_index = True)\n",
    "\n",
    "total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_and_counts(s):\n",
    "    # Imports/sets here because it'd be executed in subroutine which executes independently from main code\n",
    "    import ftfy, re, numpy as np\n",
    "    from string import punctuation, whitespace\n",
    "    \n",
    "    # Всі коди дефісу(або аналогічних символів) які я знайшов в текстах\n",
    "    dashes = [chr(int(d, 16)) for d in ['058A', '05BE', '1400', '1806', '2010', '2011',\\\n",
    "          '2012', '2013', '2014', '2015', '2053', '207B', '208B', '2212', '2E17', \\\n",
    "          '2E1A', '2E3A', '2E3B', '2E40', '2E5D', '301C', '3030', '30A0', 'FE31', \\\n",
    "          'FE32', 'FE58', 'FE63', 'FF0D', '10EAD']]\n",
    "    dashes_compiled = re.compile('[' + ''.join(dashes) + ']+', flags = re.UNICODE)\n",
    "    \n",
    "    s = ftfy.fix_text(s)\n",
    "    s = re.sub(dashes_compiled, '-', s)     # all dashes should be the same\n",
    "\n",
    "    url_n = len(re.findall('https?://\\\\S+\\\\b', s)) # count urls\n",
    "    s = re.sub('https?://\\\\S+\\\\b', '', s)   # and remove them\n",
    "\n",
    "    hasht_n = len(re.findall(r'#\\w+\\b', s)) # count hashtags\n",
    "    s = re.sub(r'#\\w+\\b', '', s)            # remove them\n",
    "\n",
    "    handle_n = len(re.findall(r'@\\w{1,15}\\b', s)) # count handles\n",
    "    s = re.sub(r'@\\w{1,15}\\b', '', s)       # remove them\n",
    "\n",
    "    s = re.sub('pic\\\\.twitter\\\\.com/\\\\w+\\\\b', '', s)        # remove pictures. Not expected to impact overall results\n",
    "    s = re.sub('\\\\s+', ' ', s)                              # reducing multiple whitespaces to one\n",
    "    s = s.lstrip(whitespace + punctuation + '\\xa0' + chr(8230))   # removing possible whitespaces in front\n",
    "    s = s.rstrip(whitespace + '\\xa0')         # and on the back\n",
    "    l=''\n",
    "    emoj_and_such = 0\n",
    "    for ch in s:\n",
    "        if ord(ch) < 8204:\n",
    "            l += ch             # keep a symbol if not emoji or pictogram or such\n",
    "        else:\n",
    "            emoj_and_such += 1  # counting emojis and pictograms\n",
    "    comma_n = len(re.findall(',', s))\n",
    "    exl_n =  len(re.findall('!', s))\n",
    "    dash_n = len(re.findall('-', s))\n",
    "    a_an_n = len(re.findall(r'\\b[Aa]n?\\b', s))\n",
    "    the_n = len(re.findall(r'\\b[Tt]he\\b', s))\n",
    "\n",
    "    # reduce a number of repeated symbols to no more than 2 \n",
    "    l = re.sub(r'(.)\\1\\1+', r'\\1\\1', l)\n",
    "    length = len(l)\n",
    "\n",
    "    words = [len(w) for w in re.findall(r'\\b\\w+\\b', l)]\n",
    "    if len(words)==0:\n",
    "        average_word = 0\n",
    "    else:\n",
    "        average_word = np.max(words)\n",
    "    \n",
    "    return l, url_n, hasht_n, handle_n, emoj_and_such, exl_n, comma_n, dash_n, a_an_n, the_n, length, average_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.5 s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Multithreaded pre-processing of dataframe\n",
    "with mp.Pool(processes= mp.cpu_count()) as p:\n",
    "    total_data['tuple'] = p.map(cleaning_and_counts, total_data.tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Після обробки треба розпакувати результат в колонки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = (\"cleaned_tweet, url_n, hasht_n, handle_n, emoji_and_such, exl_n, comma_n, dash_n, a_an_n, the_n, length, average_word\").split(', ')\n",
    "\n",
    "for i in range(len(features)):\n",
    "    if i == 0:\n",
    "        total_data[features[i]] = total_data.tuple.apply(lambda t: t[i])\n",
    "    else:\n",
    "        total_data[features[i]] = total_data.tuple.apply(lambda t: t[i]).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очистка пам'яті, бо даних дуже багато"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['account', 'tweet', 'troll', 'tuple', 'cleaned_tweet', 'url_n',\n",
      "       'hasht_n', 'handle_n', 'emoji_and_such', 'exl_n', 'comma_n', 'dash_n',\n",
      "       'a_an_n', 'the_n', 'length', 'average_word'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(total_data.columns)\n",
    "total_data.drop(['tuple'], axis=1,inplace=True)\n",
    "del full_ru_trolls_en, celebs, sentiment140\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видаляю акаунти, які містять менше 10 твітів.\n",
    "* Причина: Аналіз діяльності облікових записів, в контексті якого 1 публікація не дає достатньо інформації."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account</th>\n",
       "      <th>troll</th>\n",
       "      <th>url_n</th>\n",
       "      <th>hasht_n</th>\n",
       "      <th>handle_n</th>\n",
       "      <th>emoji_and_such</th>\n",
       "      <th>exl_n</th>\n",
       "      <th>comma_n</th>\n",
       "      <th>dash_n</th>\n",
       "      <th>a_an_n</th>\n",
       "      <th>the_n</th>\n",
       "      <th>length</th>\n",
       "      <th>average_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>various</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>various</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>various</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>various</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>various</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3901564</th>\n",
       "      <td>_SOLOMONALBERT_</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3901565</th>\n",
       "      <td>_SOLOMONALBERT_</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3901566</th>\n",
       "      <td>_SOLOMONALBERT_</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3901567</th>\n",
       "      <td>_SOLOMONALBERT_</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3901568</th>\n",
       "      <td>_SOLOMONALBERT_</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2729854 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 account  troll  url_n  hasht_n  handle_n  emoji_and_such  \\\n",
       "0                various      0      1        4         1               0   \n",
       "1                various      0      1        1         1               0   \n",
       "2                various      0      0        0         3               0   \n",
       "3                various      0      1        4         1               0   \n",
       "4                various      0      1        2         0               0   \n",
       "...                  ...    ...    ...      ...       ...             ...   \n",
       "3901564  _SOLOMONALBERT_      1      0        2         0               0   \n",
       "3901565  _SOLOMONALBERT_      1      2        4         1               0   \n",
       "3901566  _SOLOMONALBERT_      1      0        2         0               1   \n",
       "3901567  _SOLOMONALBERT_      1      0        3         0               0   \n",
       "3901568  _SOLOMONALBERT_      1      0        1         0               0   \n",
       "\n",
       "         exl_n  comma_n  dash_n  a_an_n  the_n  length  average_word  \n",
       "0            0        0       0       0      0      15             6  \n",
       "1            0        0       1       1      0      39             9  \n",
       "2            0        0       0       0      0      18             4  \n",
       "3            0        1       1       0      0      57            10  \n",
       "4            1        0       0       0      0      55             9  \n",
       "...        ...      ...     ...     ...    ...     ...           ...  \n",
       "3901564      0        0       0       2      0      81             7  \n",
       "3901565      0        0       0       0      0      12             7  \n",
       "3901566      0        0       0       0      0      64            10  \n",
       "3901567      0        0       0       0      1      52             9  \n",
       "3901568      0        1       0       0      0      66             9  \n",
       "\n",
       "[2729854 rows x 13 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_count = 10\n",
    "acc_properties = total_data[['account', 'troll']].groupby(['account'])\\\n",
    "    .agg(tweet_count=('account', 'size'),troll = ('troll','min'))\\\n",
    "    .reset_index()\n",
    "kept_accs = acc_properties[acc_properties.tweet_count >= min_count]\n",
    "restricted = total_data[total_data.account.isin(kept_accs.account)].copy(deep=True)\n",
    "del total_data\n",
    "\n",
    "num_cols = features[1:]\n",
    "restricted.drop(['tweet', 'cleaned_tweet'], axis=1, inplace=True)\n",
    "restricted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обчислення персентилів і шафл даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentile_calc(data, groupby_col, num_cols, percentile_list):\n",
    "    non_numeric = [col_name for col_name in data.columns if col_name not in num_cols]\n",
    "    for qu in percentile_list: \n",
    "        percentiles = data.groupby(groupby_col).quantile(q=qu/100).reset_index()\n",
    "        cols_to_change = {col : col +'_' + str(qu) for col in num_cols}\n",
    "        percentiles.rename(columns=cols_to_change, inplace=True)\n",
    "        if qu == percentile_list[0]:\n",
    "            all_percentiles = percentiles\n",
    "        else:\n",
    "            all_percentiles = pd.merge(all_percentiles, percentiles, how = \"left\",\\\n",
    "                                       on = non_numeric)\n",
    "    return all_percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 6.77 s\n",
      "Wall time: 9.3 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account</th>\n",
       "      <th>troll</th>\n",
       "      <th>url_n_10</th>\n",
       "      <th>hasht_n_10</th>\n",
       "      <th>handle_n_10</th>\n",
       "      <th>emoji_and_such_10</th>\n",
       "      <th>exl_n_10</th>\n",
       "      <th>comma_n_10</th>\n",
       "      <th>dash_n_10</th>\n",
       "      <th>a_an_n_10</th>\n",
       "      <th>...</th>\n",
       "      <th>hasht_n_90</th>\n",
       "      <th>handle_n_90</th>\n",
       "      <th>emoji_and_such_90</th>\n",
       "      <th>exl_n_90</th>\n",
       "      <th>comma_n_90</th>\n",
       "      <th>dash_n_90</th>\n",
       "      <th>a_an_n_90</th>\n",
       "      <th>the_n_90</th>\n",
       "      <th>length_90</th>\n",
       "      <th>average_word_90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dannyatticus</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119.8</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mikeinsd77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>125.8</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chricket</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>116.5</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>victoriaamarie</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>118.7</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MRMUSTACHEE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23267</th>\n",
       "      <td>tinknevertalks</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>120.6</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23268</th>\n",
       "      <td>ashaazaaa</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>70.6</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23269</th>\n",
       "      <td>BADDESTNLA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.8</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23270</th>\n",
       "      <td>LauraKalbag</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>114.6</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23271</th>\n",
       "      <td>neeshaaaa</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>89.4</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23272 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              account  troll  url_n_10  hasht_n_10  handle_n_10  \\\n",
       "0        dannyatticus    0.0       0.0         0.0          0.0   \n",
       "1          mikeinsd77    0.0       0.0         0.0          0.0   \n",
       "2            chricket    0.0       0.0         0.0          0.0   \n",
       "3      victoriaamarie    0.0       0.0         0.0          0.0   \n",
       "4         MRMUSTACHEE    1.0       0.0         1.0          0.0   \n",
       "...               ...    ...       ...         ...          ...   \n",
       "23267  tinknevertalks    0.0       0.0         0.0          0.0   \n",
       "23268       ashaazaaa    0.0       0.0         0.0          0.0   \n",
       "23269      BADDESTNLA    0.0       0.0         0.0          0.0   \n",
       "23270     LauraKalbag    0.0       0.0         0.0          1.0   \n",
       "23271       neeshaaaa    0.0       0.0         0.0          0.0   \n",
       "\n",
       "       emoji_and_such_10  exl_n_10  comma_n_10  dash_n_10  a_an_n_10  ...  \\\n",
       "0                    0.0       0.0         0.0        0.0        0.0  ...   \n",
       "1                    0.0       0.0         0.0        0.0        0.0  ...   \n",
       "2                    0.0       0.0         0.0        0.0        0.0  ...   \n",
       "3                    0.0       0.0         0.0        0.0        0.0  ...   \n",
       "4                    0.0       0.0         0.0        0.0        0.0  ...   \n",
       "...                  ...       ...         ...        ...        ...  ...   \n",
       "23267                0.0       0.0         0.0        0.0        0.0  ...   \n",
       "23268                0.0       0.0         0.0        0.0        0.0  ...   \n",
       "23269                0.0       0.0         0.0        0.0        0.0  ...   \n",
       "23270                0.0       0.0         0.0        0.0        0.0  ...   \n",
       "23271                0.0       0.0         0.0        0.0        0.0  ...   \n",
       "\n",
       "       hasht_n_90  handle_n_90  emoji_and_such_90  exl_n_90  comma_n_90  \\\n",
       "0             0.0          1.0                0.0       0.4         1.0   \n",
       "1             0.0          1.0                0.0       0.0         2.0   \n",
       "2             0.0          1.0                0.0       1.0         0.0   \n",
       "3             0.0          0.9                0.0       1.0         0.0   \n",
       "4             3.0          0.0                0.4       0.0         1.0   \n",
       "...           ...          ...                ...       ...         ...   \n",
       "23267         0.0          1.0                0.0       1.0         1.4   \n",
       "23268         0.0          0.0                0.0       0.0         1.3   \n",
       "23269         0.0          1.0                0.0       0.0         0.0   \n",
       "23270         0.0          1.0                0.0       1.2         1.0   \n",
       "23271         0.0          1.0                0.0       1.6         1.0   \n",
       "\n",
       "       dash_n_90  a_an_n_90  the_n_90  length_90  average_word_90  \n",
       "0            0.0        2.0       1.0      119.8              9.4  \n",
       "1            0.0        1.0       1.0      125.8              9.0  \n",
       "2            0.0        1.0       0.7      116.5              9.7  \n",
       "3            0.0        1.0       1.0      118.7              9.0  \n",
       "4            0.0        0.4       1.0       78.0             12.0  \n",
       "...          ...        ...       ...        ...              ...  \n",
       "23267        0.0        1.0       1.4      120.6             10.0  \n",
       "23268        0.0        1.0       0.3       70.6              9.0  \n",
       "23269        0.0        1.0       1.0       86.8              9.0  \n",
       "23270        0.2        1.0       1.0      114.6              9.0  \n",
       "23271        0.0        0.0       1.6       89.4              9.6  \n",
       "\n",
       "[23272 rows x 101 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "all_percentiles = percentile_calc(restricted[['account', 'troll']+num_cols], \\\n",
    "                                 groupby_col='account', num_cols=num_cols,\n",
    "                                 percentile_list=range(10, 100, 10))\n",
    "    \n",
    "new_features = all_percentiles.columns[2:]\n",
    "all_percentiles = shuffle(all_percentiles).reset_index(drop = True)\n",
    "all_percentiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель. Тренування і тести"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кастомний scikit-learn Transformer для виключення фіч методами MI та Кореляції Пірсона (протестовано і гарно працює). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _drop_correlated(data, score_ordered_cols, max_corr, method='pearson'):\n",
    "    new = [[score_ordered_cols[0]], [0]]\n",
    "    corr_matrix = data[score_ordered_cols].corr(method).values\n",
    "    N = len(score_ordered_cols)\n",
    "    for i in range(1, N):\n",
    "        tr = corr_matrix[new[1], i]\n",
    "        if sum(np.abs(tr) > max_corr) == 0:\n",
    "            new[0] += [score_ordered_cols[i]]\n",
    "            new[1] += [i]\n",
    "    return new[0]\n",
    "\n",
    "\n",
    "class feature_reduction(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, min_mi=.001, max_corr=.7, n_neighbors=11):\n",
    "        self.min_mi = min_mi\n",
    "        self.max_corr = max_corr\n",
    "        self.n_neighbors = n_neighbors\n",
    "\n",
    "    def fit(self, X:pd.DataFrame, y):\n",
    "        X = X.copy(deep=True)\n",
    "        columns = X.columns\n",
    "        mi = mutual_info_classif(X.values, y, n_neighbors= self.n_neighbors)\n",
    "        cols_mi = list(zip(columns, mi))\n",
    "        cols_mi.sort(reverse=True, key=lambda x: x[1])\n",
    "        cols_mi = [pair[0] for pair in cols_mi if pair[1] > self.min_mi]\n",
    "        new_cols = _drop_correlated(X[cols_mi], cols_mi, max_corr=self.max_corr)\n",
    "        self.selected_cols = new_cols\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.selected_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchcv_best(estimator):\n",
    "    print(\" The best AUC score on a train set is:\\n\", estimator.best_score_)\n",
    "    print(\" The best parameters are:\\n\", estimator.best_params_)\n",
    "\n",
    "def scores(y_test, y_pred):\n",
    "    print('===== Metrics on a test set =====')\n",
    "    print(\"A confusion matrix is:\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    print('accuracy:', accuracy_score(y_test, y_pred), \n",
    "        '\\nf1:', f1_score(y_test, y_pred),\n",
    "        '\\nprecision:', precision_score(y_test, y_pred), \n",
    "        '\\nrecall:', recall_score(y_test, y_pred), \n",
    "        '\\nroc_auc:', roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pipe_cv(data, columns, parameters, fr_params, cbc_params,cv=5, train_size=.8, scoring='roc_auc'):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data[columns], data['troll'], train_size = train_size, stratify = data['troll'])\n",
    "    fr = feature_reduction(**fr_params)\n",
    "    model = CatBoostClassifier(**cbc_params)\n",
    "    pipe = Pipeline([('mi_calc', fr), ('catboost', model)])\n",
    "    search = GridSearchCV(pipe, param_grid=parameters, cv = cv, scoring= scoring, n_jobs=-1, verbose=1)\n",
    "    search.fit(X_train, y_train)\n",
    "    searchcv_best(search)\n",
    "    y_pred = search.predict(X_test)\n",
    "    scores(y_test, y_pred)\n",
    "    return search, search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      " The best AUC score on a train set is:\n",
      " 0.9994725742386127\n",
      " The best parameters are:\n",
      " {'catboost__depth': 11, 'mi_calc__max_corr': 0.7, 'mi_calc__n_neighbors': 19}\n",
      "===== Metrics on a test set =====\n",
      "A confusion matrix is:\n",
      "[[4368   10]\n",
      " [   6  271]]\n",
      "accuracy: 0.99656283566058 \n",
      "f1: 0.9713261648745519 \n",
      "precision: 0.9644128113879004 \n",
      "recall: 0.9783393501805054 \n",
      "roc_auc: 0.9880276010838572\n",
      "CPU times: total: 17.1 s\n",
      "Wall time: 5min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipe_params = {'mi_calc__max_corr': [0.7, 0.75],\n",
    "               'mi_calc__n_neighbors': [5, 19],\n",
    "               'catboost__depth': [9, 11]}\n",
    "\n",
    "fr_params = {'min_mi': 0.0005}\n",
    "cbc_params = {\n",
    "    'loss_function': 'Logloss', \n",
    "    \n",
    "    'rsm': 0.25, \n",
    "    'l2_leaf_reg': 4, \n",
    "    'custom_metric': 'AUC',\n",
    "    \n",
    "    'logging_level': 'Silent',\n",
    "    #'task_type': 'GPU'\n",
    "}\n",
    "\n",
    "model, cv_best_params = train_pipe_cv(all_percentiles, new_features,parameters=pipe_params, fr_params=fr_params,\\\n",
    "                 cbc_params=cbc_params, scoring ='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hasht_n_90',\n",
       " 'url_n_90',\n",
       " 'url_n_50',\n",
       " 'hasht_n_50',\n",
       " 'handle_n_70',\n",
       " 'average_word_90',\n",
       " 'average_word_60',\n",
       " 'handle_n_40',\n",
       " 'emoji_and_such_90',\n",
       " 'handle_n_90',\n",
       " 'hasht_n_10',\n",
       " 'length_30',\n",
       " 'average_word_20',\n",
       " 'exl_n_90',\n",
       " 'dash_n_90',\n",
       " 'length_80',\n",
       " 'comma_n_90',\n",
       " 'handle_n_20',\n",
       " 'comma_n_70',\n",
       " 'exl_n_50',\n",
       " 'a_an_n_70',\n",
       " 'a_an_n_80',\n",
       " 'the_n_90',\n",
       " 'comma_n_50',\n",
       " 'emoji_and_such_70',\n",
       " 'the_n_60',\n",
       " 'a_an_n_60',\n",
       " 'a_an_n_90',\n",
       " 'the_n_80',\n",
       " 'the_n_70',\n",
       " 'a_an_n_50',\n",
       " 'exl_n_20',\n",
       " 'the_n_50',\n",
       " 'dash_n_70',\n",
       " 'emoji_and_such_50',\n",
       " 'comma_n_30',\n",
       " 'a_an_n_30']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in cv_best_params:\n",
    "    if key[:3] == 'cat':\n",
    "        cbc_params[key.split('__')[1]] = cv_best_params[key]\n",
    "    else:\n",
    "        fr_params[key.split('__')[1]] = cv_best_params[key]\n",
    "\n",
    "fr_cols = feature_reduction(**fr_params)\n",
    "fr_cols.fit(all_percentiles[new_features], all_percentiles.troll)\n",
    "new_cols = fr_cols.selected_cols\n",
    "new_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Список фіч, упорядкованих за обчисленою важливістю. \n",
    "\n",
    "Вони дещо змінюються з кожним повторним запуском, хоча перші, як правило, залишаються вище в списку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A number of variables is 37\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(8.857295146550172, 'url_n_90'),\n",
       " (8.713204965596162, 'average_word_90'),\n",
       " (6.997567220013056, 'hasht_n_90'),\n",
       " (6.991269212699155, 'length_30'),\n",
       " (5.757704940891846, 'exl_n_90'),\n",
       " (5.489514988849892, 'length_80'),\n",
       " (5.4434630881202635, 'handle_n_70'),\n",
       " (5.311304124567704, 'comma_n_90'),\n",
       " (4.952976728744958, 'handle_n_40'),\n",
       " (4.7492990160008555, 'handle_n_20'),\n",
       " (3.9950592147743453, 'average_word_20'),\n",
       " (3.2938309130147645, 'handle_n_90'),\n",
       " (3.21619381679535, 'average_word_60'),\n",
       " (3.013813751932447, 'dash_n_90'),\n",
       " (2.740493567523952, 'comma_n_70'),\n",
       " (2.4670590146885587, 'the_n_90'),\n",
       " (2.235395486866762, 'exl_n_50'),\n",
       " (2.0266133405015645, 'a_an_n_90'),\n",
       " (2.0062230128522502, 'a_an_n_70'),\n",
       " (1.6342957518359635, 'url_n_50'),\n",
       " (1.4573030401368232, 'the_n_80'),\n",
       " (1.126306837164903, 'a_an_n_80'),\n",
       " (1.0748099970969158, 'hasht_n_50'),\n",
       " (0.9635185636293575, 'the_n_70'),\n",
       " (0.9607086633100631, 'comma_n_50'),\n",
       " (0.912655657107789, 'emoji_and_such_90'),\n",
       " (0.876549168701829, 'dash_n_70'),\n",
       " (0.840764391516177, 'the_n_60'),\n",
       " (0.6598341277787486, 'the_n_50'),\n",
       " (0.4336561154734613, 'comma_n_30'),\n",
       " (0.34915935673617393, 'hasht_n_10'),\n",
       " (0.3167056828520055, 'a_an_n_60'),\n",
       " (0.07115278327976648, 'exl_n_20'),\n",
       " (0.03194264652930372, 'a_an_n_30'),\n",
       " (0.015424258526596752, 'emoji_and_such_70'),\n",
       " (0.012935291488705696, 'a_an_n_50'),\n",
       " (0.003996115851340688, 'emoji_and_such_50')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbc_best = CatBoostClassifier(**cbc_params)\n",
    "cbc_best.fit(all_percentiles[new_cols], all_percentiles.troll.values)\n",
    "var_importance = list(zip(cbc_best.feature_importances_, new_cols))\n",
    "var_importance.sort(key=lambda x:x[0], reverse=True)\n",
    "print(\"A number of variables is \"+str(len(new_cols)))\n",
    "var_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Висновки \n",
    "Як ми бачимо, найважливішим для виявлення тролів є те, як вони дотримуються своїх інструкцій. \n",
    "- Боти повинні включати конкретні слова у свої тексти, тому середня довжина слова відрізняється від того, що використовують звичайні користувачі. \n",
    "- Боти використовують кілька способів збільшити свою аудиторію: посилання, хештеги, хендлери Twitter, і це дуже помітно. \n",
    "- Боти швидше за все мають вказівки щодо довжини публікації. Це дуже зручно, тому що потенційно є можливість налаштувати фільтри для виявлення найбільш значущих показників, а вже потім перевірити всю активність облікового запису.\n",
    "- ! Виявилося, що запропоновані фічі не дуже залежать від мов, а здебільшого від активності акаунта троля. Таким чином, ми можемо застосувати цю роботу для інших мов, а не обмежуватися російськими тролями, які розміщують англійські тексти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_test.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.save_model(\"catboost_model.cbm\", format=\"cbm\")\n",
    "temp = model.best_estimator_.named_steps['catboost']\n",
    "temp.save_model(\"catboost_model.cbm\", format=\"cbm\")\n",
    "\n",
    "import joblib\n",
    "joblib.dump(model, 'model_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ! Realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 108 entries, 0 to 107\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   account  108 non-null    object\n",
      " 1   tweet    108 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.8+ KB\n",
      "Index(['account', 'tweet', 'tuple', 'cleaned_tweet', 'url_n', 'hasht_n',\n",
      "       'handle_n', 'emoji_and_such', 'exl_n', 'comma_n', 'dash_n', 'a_an_n',\n",
      "       'the_n', 'length', 'average_word'],\n",
      "      dtype='object')\n",
      "    account                                              tweet  \\\n",
      "0    10_GOP  \"We have a sitting Democrat US Senator on tria...   \n",
      "1    10_GOP  Marshawn Lynch arrives to game in anti-Trump s...   \n",
      "2    10_GOP  Daughter of fallen Navy Sailor delivers powerf...   \n",
      "3    10_GOP  JUST IN: President Trump dedicates Presidents ...   \n",
      "4    10_GOP  19,000 RESPECTING our National Anthem! #StandF...   \n",
      "..      ...                                                ...   \n",
      "103  10_GOP  Trump after military meeting \"It's the calm be...   \n",
      "104  10_GOP  Dear @YouTube @TeamYouTube,  Your response is ...   \n",
      "105  10_GOP  Rep. @SteveScalise started off Game 1 of the N...   \n",
      "106  10_GOP  How many of those raging over Mike Pence exerc...   \n",
      "107  10_GOP  Mike Pence is such a great man and Patriot! I'...   \n",
      "\n",
      "                                         cleaned_tweet  url_n  hasht_n  \\\n",
      "0    We have a sitting Democrat US Senator on trial...      1        0   \n",
      "1    Marshawn Lynch arrives to game in anti-Trump s...      1        0   \n",
      "2    Daughter of fallen Navy Sailor delivers powerf...      1        1   \n",
      "3    JUST IN: President Trump dedicates Presidents ...      1        0   \n",
      "4               19,00 RESPECTING our National Anthem!       1        1   \n",
      "..                                                 ...    ...      ...   \n",
      "103  Trump after military meeting \"It's the calm be...      1        0   \n",
      "104  Dear , Your response is bullshit. It's not tru...      1        0   \n",
      "105  Rep. started off Game 1 of the National League...      2        0   \n",
      "106  How many of those raging over Mike Pence exerc...      0        0   \n",
      "107  Mike Pence is such a great man and Patriot! I'...      1        0   \n",
      "\n",
      "     handle_n  emoji_and_such  exl_n  comma_n  dash_n  a_an_n  the_n  length  \\\n",
      "0           1               0      0        0       0       2      1     122   \n",
      "1           0               0      0        0       1       0      1     116   \n",
      "2           0               0      0        1       0       0      0     106   \n",
      "3           0               0      0        1       0       0      1     121   \n",
      "4           0               2      1        1       0       0      0      38   \n",
      "..        ...             ...    ...      ...     ...     ...    ...     ...   \n",
      "103         0               0      0        0       0       0      2     126   \n",
      "104         2               0      0        1       0       0      0      82   \n",
      "105         1               0      0        0       0       0      2     102   \n",
      "106         0               0      0        0       0       0      2     139   \n",
      "107         0               0      1        0       0       1      1     105   \n",
      "\n",
      "     average_word  \n",
      "0              10  \n",
      "1               8  \n",
      "2               9  \n",
      "3              10  \n",
      "4              10  \n",
      "..            ...  \n",
      "103             9  \n",
      "104             8  \n",
      "105            10  \n",
      "106            10  \n",
      "107             9  \n",
      "\n",
      "[108 rows x 14 columns]\n",
      "  account  tweet_count\n",
      "0  10_GOP          108\n",
      "Restricted\n",
      "  account  url_n_10  hasht_n_10  handle_n_10  emoji_and_such_10  exl_n_10  \\\n",
      "0  10_GOP       0.0         0.0          0.0                0.0       0.0   \n",
      "\n",
      "   comma_n_10  dash_n_10  a_an_n_10  the_n_10  ...  hasht_n_90  handle_n_90  \\\n",
      "0         0.0        0.0        0.0       0.0  ...         1.0          1.0   \n",
      "\n",
      "   emoji_and_such_90  exl_n_90  comma_n_90  dash_n_90  a_an_n_90  the_n_90  \\\n",
      "0                0.3       1.0         1.3        0.0        1.0       2.0   \n",
      "\n",
      "   length_90  average_word_90  \n",
      "0      138.0             11.3  \n",
      "\n",
      "[1 rows x 100 columns]\n",
      "Proba: [0.02983085 0.97016915]\n",
      "\n",
      "Prediction: BOT Detected\n",
      "Troll Account Probability: 0.9701691520785489\n"
     ]
    }
   ],
   "source": [
    "# msg = \"\"\"Dan Bongino: \"\"Nobody trolls liberals better than Donald Trump.\"\" Exactly!  https://t.co/AigV93aC8J #asd #sdhfj #asd #asd #asd \"\"\"\n",
    "# test_tweet = [{\"account\": \"Me My Mus\", \"tweet\": msg},\n",
    "#               {\"account\": \"Me My Mus\", \"tweet\": msg},\n",
    "#               {\"account\": \"Me My Mus\", \"tweet\": msg},\n",
    "#               {\"account\": \"Me My Mus\", \"tweet\": msg},\n",
    "#               {\"account\": \"Me My Mus\", \"tweet\": msg},\n",
    "#               {\"account\": \"Me My Mus\", \"tweet\": msg},\n",
    "#               {\"account\": \"Me My Mus\", \"tweet\": msg},\n",
    "#               {\"account\": \"Me My Mus\", \"tweet\": msg},\n",
    "#               {\"account\": \"Me My Mus\", \"tweet\": msg},\n",
    "#               {\"account\": \"Me My Mus\", \"tweet\": msg},\n",
    "#               ]\n",
    "#test_df = pd.DataFrame(test_tweet)\n",
    "\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "test_df = test_df[['account', 'tweet']]\n",
    "#test_df.to_csv(\"test_data.csv\", index=False)\n",
    "test_df.info()\n",
    "\n",
    "# Cleaning\n",
    "with mp.Pool(processes= mp.cpu_count()) as p:\n",
    "    test_df['tuple'] = p.map(cleaning_and_counts, test_df.tweet)\n",
    "\n",
    "# Memory Optimization\n",
    "features = (\"cleaned_tweet, url_n, hasht_n, handle_n, emoji_and_such, exl_n, comma_n, dash_n, a_an_n, the_n, length, average_word\").split(', ')\n",
    "\n",
    "for i in range(len(features)):\n",
    "    if i ==0:\n",
    "        test_df[features[i]] = test_df.tuple.apply(lambda t: t[i])\n",
    "    else:\n",
    "        test_df[features[i]] = test_df.tuple.apply(lambda t: t[i]).astype(np.uint8)\n",
    "\n",
    "print(test_df.columns)\n",
    "test_df.drop(['tuple'], axis=1,inplace=True)\n",
    "gc.collect()\n",
    "\n",
    "print(test_df)\n",
    "\n",
    "# Check if total account tweets > 10\n",
    "\n",
    "_min_count = 10\n",
    "_acc_properties = test_df[['account']].groupby(['account'])\\\n",
    "    .agg(tweet_count=('account', 'size'))\\\n",
    "    .reset_index()\n",
    "\n",
    "print(_acc_properties)\n",
    "_kept_accs = _acc_properties[_acc_properties.tweet_count >= _min_count]\n",
    "_restricted = test_df[test_df.account.isin(_kept_accs.account)].copy(deep=True)\n",
    "#del total_data\n",
    "\n",
    "_num_cols = features[1:]\n",
    "_restricted.drop(['tweet', 'cleaned_tweet'], axis=1, inplace=True)\n",
    "print(\"Restricted\")\n",
    "_restricted\n",
    "\n",
    "\n",
    "# Generate features\n",
    "_all_percentiles = percentile_calc(_restricted[['account']+num_cols], \\\n",
    "                                 groupby_col='account', num_cols=_num_cols,\n",
    "                                 percentile_list=range(10, 100, 10))\n",
    "    \n",
    "_new_features = _all_percentiles.columns[2:]\n",
    "print(_all_percentiles)\n",
    "\n",
    "preditction = model.predict(_all_percentiles)\n",
    "prediction_proba = model.predict_proba(_all_percentiles)[0]\n",
    "\n",
    "print(f\"Proba: {prediction_proba}\")\n",
    "\n",
    "\n",
    "print(\"\\nPrediction: \" + (\"BOT Detected\" if preditction == 1 else \"Regular User\"))\n",
    "print(\"Troll Account Probability: \" + str(prediction_proba[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
